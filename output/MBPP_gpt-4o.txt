Extracting testcases and running them...
Loading processed functions from unfiltered_testcases/MBPP_gpt-4o_processed.pkl...
423
422
{'input_mean': 33.94, 'input_max': 33.94, 'input_min': 33.94, 'input_sum': 33.94, 'input_total': 1, 'input_variance': 0.0, 'output_mean': 100.0, 'output_max': 100.0, 'output_min': 100.0, 'output_sum': 100.0, 'output_total': 1, 'output_variance': 0.0, 'second_output_mean': 0.0, 'second_output_max': 0.0, 'second_output_min': 0.0, 'second_output_sum': 0.0, 'second_output_total': 1, 'second_output_variance': 0.0, 'second_input_mean': 16.03, 'second_input_max': 16.03, 'second_input_min': 16.03, 'second_input_sum': 16.03, 'second_input_total': 1, 'second_input_variance': 0.0, 'is_valid': 1, 'function_id': 0}
Sample feature: {'input_mean': 33.94, 'input_max': 33.94, 'input_min': 33.94, 'input_sum': 33.94, 'input_total': 1, 'input_variance': 0.0, 'output_mean': 100.0, 'output_max': 100.0, 'output_min': 100.0, 'output_sum': 100.0, 'output_total': 1, 'output_variance': 0.0, 'second_output_mean': 0.0, 'second_output_max': 0.0, 'second_output_min': 0.0, 'second_output_sum': 0.0, 'second_output_total': 1, 'second_output_variance': 0.0, 'second_input_mean': 16.03, 'second_input_max': 16.03, 'second_input_min': 16.03, 'second_input_sum': 16.03, 'second_input_total': 1, 'second_input_variance': 0.0, 'is_valid': 1, 'function_id': 0}
75.64986529753624    98.28101672129253    10.575689334851939    1.0356293324107455
74.81700169032747   89.92656220907315    10.72523346339632    4.841256212093376
Balanced dataset size - Number of valid testcases: 5456
Balanced dataset size - Number of invalid testcases: 2274
Valid Testcase Ratio" 0.71
calculating initial coverage of the functions and mutation score....
The total number of tests for mutation testing: 5456
running mutation testing...
Running pytest to check tests...
All tests passed.

Final Mutation Testing Results:
Total mutants: 3057
Killed mutants: 2508
Survived mutants: 501
Timeout mutants: 44
Suspicious mutants: 4
Overall Mutation Score: 0.82%
Initial coverage:
0.969

Training and evaluating model: ensemble
[LightGBM] [Info] Number of positive: 4345, number of negative: 1839
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4977
[LightGBM] [Info] Number of data points in the train set: 6184, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.702620 -> initscore=0.859804
[LightGBM] [Info] Start training from score 0.859804
[LightGBM] [Info] Number of positive: 4378, number of negative: 1806
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4962
[LightGBM] [Info] Number of data points in the train set: 6184, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.707956 -> initscore=0.885478
[LightGBM] [Info] Start training from score 0.885478
[LightGBM] [Info] Number of positive: 4343, number of negative: 1841
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000766 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4957
[LightGBM] [Info] Number of data points in the train set: 6184, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.702296 -> initscore=0.858256
[LightGBM] [Info] Start training from score 0.858256
[LightGBM] [Info] Number of positive: 4367, number of negative: 1817
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000784 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4968
[LightGBM] [Info] Number of data points in the train set: 6184, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.706177 -> initscore=0.876889
[LightGBM] [Info] Start training from score 0.876889
[LightGBM] [Info] Number of positive: 4391, number of negative: 1793
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000771 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 4960
[LightGBM] [Info] Number of data points in the train set: 6184, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.710058 -> initscore=0.895667
[LightGBM] [Info] Start training from score 0.895667
Model: ensemble
Threshold: 0.8
=== Selection Statistics ===
Total selected instances: 2555
The ratio valid test cases: 0.796
============================
Calculating coverage and mutation score using filtered test cases...
The total number of tests for mutation testing: 2035
running mutation testing...
Running pytest to check tests...
All tests passed.

Final Mutation Testing Results:
Total mutants: 2872
Killed mutants: 2260
Survived mutants: 568
Timeout mutants: 43
Suspicious mutants: 1
Overall Mutation Score: 0.79%
{'ensemble': {'coverage': 0.96, 'total_selected': 2555, 'valid_test_case_ration': 0.796}}
Saving filtered functions to filtered_testcases/MBPP_gpt-4o.pkl...
