Extracting testcases and running them...
Loading processed functions from unfiltered_testcases/LeetCode_llama3_processed.pkl...
474
472
{'input_mean': 0.40749005159567925, 'input_max': 0.7491097378021877, 'input_min': 0.04085052880709807, 'input_sum': 2.4449403095740756, 'input_total': 6, 'input_variance': 0.06372169903942125, 'is_valid': 1, 'function_id': 0}
Balanced dataset size - Number of valid testcases: 2325
Balanced dataset size - Number of invalid testcases: 2698
Valid Testcase Ratio" 0.46
calculating initial coverage of the functions and mutation score....

Training and evaluating model: ensemble
[LightGBM] [Info] Number of positive: 1881, number of negative: 2137
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1308
[LightGBM] [Info] Number of data points in the train set: 4018, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468143 -> initscore=-0.127599
[LightGBM] [Info] Start training from score -0.127599
[LightGBM] [Info] Number of positive: 1786, number of negative: 2232
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000125 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1306
[LightGBM] [Info] Number of data points in the train set: 4018, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.444500 -> initscore=-0.222920
[LightGBM] [Info] Start training from score -0.222920
[LightGBM] [Info] Number of positive: 1915, number of negative: 2103
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1309
[LightGBM] [Info] Number of data points in the train set: 4018, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476605 -> initscore=-0.093647
[LightGBM] [Info] Start training from score -0.093647
[LightGBM] [Info] Number of positive: 1843, number of negative: 2176
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1310
[LightGBM] [Info] Number of data points in the train set: 4019, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.458572 -> initscore=-0.166094
[LightGBM] [Info] Start training from score -0.166094
[LightGBM] [Info] Number of positive: 1875, number of negative: 2144
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000096 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1307
[LightGBM] [Info] Number of data points in the train set: 4019, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.466534 -> initscore=-0.134065
[LightGBM] [Info] Start training from score -0.134065
Model: ensemble
Threshold: 0.75
=== Selection Statistics ===
Total selected instances: 1041
The ratio valid test cases: 0.668
============================
Calculating coverage and mutation score using filtered test cases...
precision: 0.67
recall: 0.30
f1_score: 0.41
{'ensemble': {'total_selected': 1041, 'valid_test_case_ration': 0.668}}
Saving filtered functions to filtered_testcases/LeetCode_llama3.pkl...
