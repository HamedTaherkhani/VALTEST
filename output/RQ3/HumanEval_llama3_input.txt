Extracting testcases and running them...
Loading processed functions from unfiltered_testcases/HumanEval_llama3_processed.pkl...
123
119
{'input_mean': 0.04811496915514805, 'input_max': 0.26129217704371555, 'input_min': 0.0002651127588649017, 'input_sum': 0.5773796298617766, 'input_total': 12, 'input_variance': 0.005806424782716348, 'is_valid': 1, 'function_id': 0}
Balanced dataset size - Number of valid testcases: 1545
Balanced dataset size - Number of invalid testcases: 914
Valid Testcase Ratio" 0.63
calculating initial coverage of the functions and mutation score....

Training and evaluating model: ensemble
[LightGBM] [Info] Number of positive: 1286, number of negative: 681
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1297
[LightGBM] [Info] Number of data points in the train set: 1967, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653787 -> initscore=0.635730
[LightGBM] [Info] Start training from score 0.635730
[LightGBM] [Info] Number of positive: 1164, number of negative: 803
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1298
[LightGBM] [Info] Number of data points in the train set: 1967, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.591764 -> initscore=0.371263
[LightGBM] [Info] Start training from score 0.371263
[LightGBM] [Info] Number of positive: 1221, number of negative: 746
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001073 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 1299
[LightGBM] [Info] Number of data points in the train set: 1967, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.620742 -> initscore=0.492700
[LightGBM] [Info] Start training from score 0.492700
[LightGBM] [Info] Number of positive: 1241, number of negative: 726
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1299
[LightGBM] [Info] Number of data points in the train set: 1967, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.630910 -> initscore=0.536123
[LightGBM] [Info] Start training from score 0.536123
[LightGBM] [Info] Number of positive: 1268, number of negative: 700
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1298
[LightGBM] [Info] Number of data points in the train set: 1968, number of used features: 6
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644309 -> initscore=0.594116
[LightGBM] [Info] Start training from score 0.594116
Model: ensemble
Threshold: 0.75
=== Selection Statistics ===
Total selected instances: 380
The ratio valid test cases: 0.647
============================
Calculating coverage and mutation score using filtered test cases...
precision: 0.65
recall: 0.16
f1_score: 0.26
{'ensemble': {'total_selected': 380, 'valid_test_case_ration': 0.647}}
Saving filtered functions to filtered_testcases/HumanEval_llama3.pkl...
