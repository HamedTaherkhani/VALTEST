Extracting testcases and running them...
Loading processed functions from unfiltered_testcases/MBPP_gpt-4o_processed.pkl...
424
423
here
{'input_mean': 33.94, 'input_max': 33.94, 'input_min': 33.94, 'input_sum': 33.94, 'input_total': 1, 'input_variance': 0.0, 'output_mean': 100.0, 'output_max': 100.0, 'output_min': 100.0, 'output_sum': 100.0, 'output_total': 1, 'output_variance': 0.0, 'is_valid': 1, 'function_id': 0}
Balanced dataset size - Number of valid testcases: 5456
Balanced dataset size - Number of invalid testcases: 2294
Valid Testcase Ratio" 0.7
calculating initial coverage of the functions and mutation score....

Training and evaluating model: ensemble
[LightGBM] [Info] Number of positive: 4310, number of negative: 1890
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2345
[LightGBM] [Info] Number of data points in the train set: 6200, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.695161 -> initscore=0.824361
[LightGBM] [Info] Start training from score 0.824361
[LightGBM] [Info] Number of positive: 4394, number of negative: 1806
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2340
[LightGBM] [Info] Number of data points in the train set: 6200, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.708710 -> initscore=0.889126
[LightGBM] [Info] Start training from score 0.889126
[LightGBM] [Info] Number of positive: 4352, number of negative: 1848
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005151 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 2352
[LightGBM] [Info] Number of data points in the train set: 6200, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.701935 -> initscore=0.856532
[LightGBM] [Info] Start training from score 0.856532
[LightGBM] [Info] Number of positive: 4409, number of negative: 1791
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2348
[LightGBM] [Info] Number of data points in the train set: 6200, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.711129 -> initscore=0.900874
[LightGBM] [Info] Start training from score 0.900874
[LightGBM] [Info] Number of positive: 4359, number of negative: 1841
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 2356
[LightGBM] [Info] Number of data points in the train set: 6200, number of used features: 12
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.703065 -> initscore=0.861934
[LightGBM] [Info] Start training from score 0.861934
Model: ensemble
Threshold: 0.75
=== Selection Statistics ===
Total selected instances: 3518
The ratio valid test cases: 0.824
============================
Calculating coverage and mutation score using filtered test cases...
precision: 0.82
recall: 0.53
f1_score: 0.65
{'ensemble': {'total_selected': 3518, 'valid_test_case_ration': 0.828}}
Saving filtered functions to filtered_testcases/MBPP_gpt-4o.pkl...
