Extracting testcases and running them...
Loading processed functions from unfiltered_testcases/LeetCode_gpt-4o_processed.pkl...
536
532
{'input_mean': 99.74600000000001, 'input_max': 100.0, 'input_min': 98.73, 'input_sum': 498.73, 'input_total': 5, 'input_variance': 0.25806399999999846, 'output_mean': 100.0, 'output_max': 100.0, 'output_min': 100.0, 'output_sum': 200.0, 'output_total': 2, 'output_variance': 0.0, 'second_output_mean': 0.0, 'second_output_max': 0.0, 'second_output_min': 0.0, 'second_output_sum': 0.0, 'second_output_total': 2, 'second_output_variance': 0.0, 'second_input_mean': 0.248, 'second_input_max': 1.24, 'second_input_min': 0.0, 'second_input_sum': 1.24, 'second_input_total': 5, 'second_input_variance': 0.24601599999999996, 'is_valid': 1, 'function_id': 0}
Sample feature: {'input_mean': 99.74600000000001, 'input_max': 100.0, 'input_min': 98.73, 'input_sum': 498.73, 'input_total': 5, 'input_variance': 0.25806399999999846, 'output_mean': 100.0, 'output_max': 100.0, 'output_min': 100.0, 'output_sum': 200.0, 'output_total': 2, 'output_variance': 0.0, 'second_output_mean': 0.0, 'second_output_max': 0.0, 'second_output_min': 0.0, 'second_output_sum': 0.0, 'second_output_total': 2, 'second_output_variance': 0.0, 'second_input_mean': 0.248, 'second_input_max': 1.24, 'second_input_min': 0.0, 'second_input_sum': 1.24, 'second_input_total': 5, 'second_input_variance': 0.24601599999999996, 'is_valid': 1, 'function_id': 0}
78.22004992054286    95.80920660764093    9.74765492237342    2.310178613648219
74.6807589090838   73.87824409799256    11.087868980281737    11.958410356357382
Balanced dataset size - Number of valid testcases: 6806
Balanced dataset size - Number of invalid testcases: 2241
Valid Testcase Ratio" 0.75
calculating initial coverage of the functions and mutation score....
The total number of tests for mutation testing: 6806
running mutation testing...
Final Mutation Testing Results:
Total mutants: 8578
Killed mutants: 7314
Survived mutants: 1010
Timeout mutants: 180
Suspicious mutants: 74
Overall Mutation Score: 85.26%
Initial coverage:
0.983

Training and evaluating model: ensemble
[LightGBM] [Info] Number of positive: 5500, number of negative: 1737
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105020 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5131
[LightGBM] [Info] Number of data points in the train set: 7237, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.759983 -> initscore=1.152589
[LightGBM] [Info] Start training from score 1.152589
[LightGBM] [Info] Number of positive: 5480, number of negative: 1757
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123780 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5131
[LightGBM] [Info] Number of data points in the train set: 7237, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.757220 -> initscore=1.137497
[LightGBM] [Info] Start training from score 1.137497
[LightGBM] [Info] Number of positive: 5412, number of negative: 1826
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.117663 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5120
[LightGBM] [Info] Number of data points in the train set: 7238, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.747720 -> initscore=1.086491
[LightGBM] [Info] Start training from score 1.086491
[LightGBM] [Info] Number of positive: 5415, number of negative: 1823
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088932 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5125
[LightGBM] [Info] Number of data points in the train set: 7238, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.748135 -> initscore=1.088689
[LightGBM] [Info] Start training from score 1.088689
[LightGBM] [Info] Number of positive: 5417, number of negative: 1821
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083912 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 5137
[LightGBM] [Info] Number of data points in the train set: 7238, number of used features: 24
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.748411 -> initscore=1.090156
[LightGBM] [Info] Start training from score 1.090156
Model: ensemble
Threshold: 0.8
=== Selection Statistics ===
Total selected instances: 5251
The ratio valid test cases: 0.946
============================
Calculating coverage and mutation score using filtered test cases...
The total number of tests for mutation testing: 4966
running mutation testing...
Final Mutation Testing Results:
Total mutants: 8088
Killed mutants: 6830
Survived mutants: 1004
Timeout mutants: 159
Suspicious mutants: 95
Overall Mutation Score: 84.45%
{'ensemble': {'coverage': 0.983, 'total_selected': 5251, 'valid_test_case_ration': 0.946}}
Saving filtered functions to filtered_testcases/LeetCode_gpt-4o.pkl...
